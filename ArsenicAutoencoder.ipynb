{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMYQOzx1hPPzSwz9Oq5hGW3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sushirito/ArsenicFR/blob/main/ArsenicAutoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Colab setup ===\n",
        "# If in Colab, run this to mount Drive\n",
        "from google.colab import drive  # safe if not in Colab\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyMX55NLGTu9",
        "outputId": "a878ca26-dec1-456a-ed29-a4e2b5e6c5b1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUlWnBMwFP3r",
        "outputId": "2a67e61c-2944-4199-9891-6036a8e1898f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wavelengths: (601,) Concentrations: [ 0. 10. 20. 30. 40. 60.] A: (601, 6)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Optional. Colab already has torch. Keep this if you want a fixed version.\n",
        "# !pip -q install torch torchvision torchaudio\n",
        "\n",
        "import os, math, time, random, pickle, json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Reproducibility and dtype\n",
        "SEED = 1337\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "try:\n",
        "    torch.set_float32_matmul_precision(\"medium\")\n",
        "except Exception:\n",
        "    pass\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Paths\n",
        "ROOT = \"/content/drive/MyDrive/ArsenicSTS\"\n",
        "DATA_CSV = f\"{ROOT}/UVVisData/0.30MB_AuNP_As.csv\"\n",
        "CKPT_ROOT = f\"{ROOT}/aae_ckpts\"\n",
        "FIG_ROOT = f\"{ROOT}/figs\"\n",
        "GEN_ROOT = f\"{ROOT}/generated\"\n",
        "os.makedirs(CKPT_ROOT, exist_ok=True)\n",
        "os.makedirs(FIG_ROOT, exist_ok=True)\n",
        "os.makedirs(GEN_ROOT, exist_ok=True)\n",
        "\n",
        "# ===== Data loader and preprocessing =====\n",
        "def load_uvvis_csv(path, baseline_correct=True):\n",
        "    \"\"\"Returns wavelengths [601], conc_list [6], A_mat [601,6] after optional baseline removal at 800 nm.\"\"\"\n",
        "    df = pd.read_csv(path)\n",
        "    # normalize column names to str\n",
        "    df.columns = [str(c).strip() for c in df.columns]\n",
        "    assert \"Wavelength\" in df.columns, \"CSV must have 'Wavelength' column\"\n",
        "    wl = df[\"Wavelength\"].to_numpy().astype(np.float32)\n",
        "    # extract concentration columns that are numeric when cast to float\n",
        "    conc_cols = []\n",
        "    for c in df.columns:\n",
        "        if c == \"Wavelength\":\n",
        "            continue\n",
        "        try:\n",
        "            float(c)\n",
        "            conc_cols.append(c)\n",
        "        except Exception:\n",
        "            pass\n",
        "    # sort by numeric concentration ascending\n",
        "    conc_vals = np.array(sorted([float(c) for c in conc_cols], key=float), dtype=np.float32)\n",
        "    conc_cols_sorted = [str(int(c)) if float(c).is_integer() else str(c) for c in conc_vals]\n",
        "    # Build matrix in that order\n",
        "    A = np.stack([df[c].to_numpy().astype(np.float32) for c in conc_cols_sorted], axis=1)  # [601,6]\n",
        "    # Optional baseline correction using A at 800 nm\n",
        "    if baseline_correct:\n",
        "        # find index of 800 nm\n",
        "        idx_800 = int(np.argmin(np.abs(wl - 800.0)))\n",
        "        base = A[idx_800:idx_800+1, :]  # [1,6]\n",
        "        A = A - base\n",
        "    return wl, conc_vals, A\n",
        "\n",
        "def split_loco(concs):\n",
        "    \"\"\"Yield folds with one held concentration each.\"\"\"\n",
        "    for c_hold in concs:\n",
        "        train = [c for c in concs if c != c_hold]\n",
        "        yield c_hold, np.array(train, dtype=np.float32)\n",
        "\n",
        "class SpectraScaler:\n",
        "    \"\"\"Featurewise standardization using training stats only. Works on [N,601] row vectors.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.mean = None\n",
        "        self.std = None\n",
        "    def fit(self, X):  # X [N,601]\n",
        "        self.mean = X.mean(axis=0, keepdims=True)\n",
        "        self.std  = X.std(axis=0, keepdims=True) + 1e-6\n",
        "    def transform(self, X):\n",
        "        return (X - self.mean) / self.std\n",
        "    def inverse(self, Xz):\n",
        "        return Xz * self.std + self.mean\n",
        "    def save(self, path):\n",
        "        with open(path, \"wb\") as f:\n",
        "            pickle.dump({\"mean\": self.mean, \"std\": self.std}, f)\n",
        "    @staticmethod\n",
        "    def load(path):\n",
        "        with open(path, \"rb\") as f:\n",
        "            d = pickle.load(f)\n",
        "        sc = SpectraScaler()\n",
        "        sc.mean, sc.std = d[\"mean\"], d[\"std\"]\n",
        "        return sc\n",
        "\n",
        "# Load data\n",
        "wl, concs_all, A = load_uvvis_csv(DATA_CSV, baseline_correct=True)  # A [601,6]\n",
        "assert A.shape[0] == 601, \"Expected 601 wavelengths\"\n",
        "assert A.shape[1] == len(concs_all), \"Mismatch in concentration columns\"\n",
        "print(\"Wavelengths:\", wl.shape, \"Concentrations:\", concs_all, \"A:\", A.shape)\n",
        "\n",
        "# Build per-spectrum dataset\n",
        "# Each column is a sample x in R^601 and scalar c in Âµg/L\n",
        "SPECTRA = {float(c): A[:, i].astype(np.float32) for i, c in enumerate(concs_all)}\n",
        "WL_MIN, WL_MAX = wl.min(), wl.max()\n",
        "C_MIN, C_MAX = float(concs_all.min()), float(concs_all.max())\n",
        "\n",
        "def scale_c(c, cmin=C_MIN, cmax=C_MAX):\n",
        "    return (c - cmin) / (cmax - cmin + 1e-12)\n",
        "\n",
        "def unscale_c(cs, cmin=C_MIN, cmax=C_MAX):\n",
        "    return cs * (cmax - cmin) + cmin\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Small MLP building block =====\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, in_dim, hidden, out_dim, n_layers=3, act=nn.SiLU, layernorm=True, final_act=None):\n",
        "        super().__init__()\n",
        "        dims = [in_dim] + [hidden]*n_layers + [out_dim]\n",
        "        layers = []\n",
        "        for i in range(len(dims)-2):\n",
        "            layers += [nn.Linear(dims[i], dims[i+1])]\n",
        "            if layernorm:\n",
        "                layers += [nn.LayerNorm(dims[i+1])]\n",
        "            layers += [act()]\n",
        "        layers += [nn.Linear(dims[-2], dims[-1])]\n",
        "        if final_act is not None:\n",
        "            layers += [final_act()]\n",
        "        self.net = nn.Sequential(*layers)\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# ===== AAE components =====\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, in_dim=601, hidden=256, latent_dim=4, n_layers=3):\n",
        "        super().__init__()\n",
        "        self.f = MLP(in_dim, hidden, latent_dim, n_layers=n_layers, act=nn.SiLU, layernorm=True)\n",
        "    def forward(self, x):\n",
        "        return self.f(x)\n",
        "\n",
        "class CEmbed(nn.Module):\n",
        "    def __init__(self, emb_dim=8):\n",
        "        super().__init__()\n",
        "        self.f = MLP(1, hidden=16, out_dim=emb_dim, n_layers=1, act=nn.SiLU, layernorm=False)\n",
        "    def forward(self, c01):\n",
        "        return self.f(c01)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_dim=4, c_emb_dim=8, hidden=256, out_dim=601, n_layers=3):\n",
        "        super().__init__()\n",
        "        self.f = MLP(latent_dim + c_emb_dim, hidden, out_dim, n_layers=n_layers, act=nn.SiLU, layernorm=True)\n",
        "    def forward(self, z, cemb):\n",
        "        h = torch.cat([z, cemb], dim=-1)\n",
        "        return self.f(h)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, latent_dim=4, hidden=128):\n",
        "        super().__init__()\n",
        "        self.f = nn.Sequential(\n",
        "            nn.Linear(latent_dim, hidden), nn.SiLU(),\n",
        "            nn.Linear(hidden, hidden), nn.SiLU(),\n",
        "            nn.Linear(hidden, 1)\n",
        "        )\n",
        "    def forward(self, z):\n",
        "        return self.f(z)  # logits\n",
        "\n",
        "class AuxRegressor(nn.Module):\n",
        "    def __init__(self, latent_dim=4):\n",
        "        super().__init__()\n",
        "        self.f = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 32), nn.SiLU(),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "    def forward(self, z):\n",
        "        return self.f(z)  # predicts c_scaled\n"
      ],
      "metadata": {
        "id": "IC8Vb_wfGi4V"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Utilities =====\n",
        "def rmse(a, b):\n",
        "    return float(np.sqrt(np.mean((a - b)**2)))\n",
        "\n",
        "def pearsonr(a, b):\n",
        "    a = a - a.mean(); b = b - b.mean()\n",
        "    return float((a*b).sum() / (np.sqrt((a*a).sum()) * np.sqrt((b*b).sum()) + 1e-12))\n",
        "\n",
        "def peak_nm(wl, spec):\n",
        "    return float(wl[int(np.argmax(spec))])\n",
        "\n",
        "def linear_baseline_interp(concs_known, A_known, c_target):\n",
        "    \"\"\"Interpolate at each wavelength separately using two nearest neighbors in conc space.\n",
        "       A_known shape [601, K] for K known concs in ascending concs_known.\"\"\"\n",
        "    concs = np.array(concs_known, dtype=np.float32)\n",
        "    A_kn = np.array(A_known, dtype=np.float32)  # [601,K]\n",
        "    # find left and right neighbors for c_target\n",
        "    if c_target <= concs.min():\n",
        "        # extrapolate using first two\n",
        "        i0, i1 = 0, 1\n",
        "    elif c_target >= concs.max():\n",
        "        i0, i1 = len(concs)-2, len(concs)-1\n",
        "    else:\n",
        "        i1 = int(np.searchsorted(concs, c_target, side=\"right\"))\n",
        "        i0 = i1 - 1\n",
        "    c0, c1 = concs[i0], concs[i1]\n",
        "    w = (c_target - c0) / (c1 - c0 + 1e-12)\n",
        "    return (1 - w) * A_kn[:, i0] + w * A_kn[:, i1]\n",
        "\n",
        "def make_batch(X, C, batch_size):\n",
        "    n = X.shape[0]\n",
        "    idx = np.random.randint(0, n, size=(batch_size,))\n",
        "    return torch.from_numpy(X[idx]).float().to(DEVICE), torch.from_numpy(C[idx]).float().to(DEVICE)\n",
        "\n",
        "def save_fold_artifacts(fold_dir, enc, dec, disc, aux, scaler, meta):\n",
        "    os.makedirs(fold_dir, exist_ok=True)\n",
        "    torch.save(enc.state_dict(),  os.path.join(fold_dir, \"encoder.pt\"))\n",
        "    torch.save(dec.state_dict(),  os.path.join(fold_dir, \"decoder.pt\"))\n",
        "    torch.save(disc.state_dict(), os.path.join(fold_dir, \"disc.pt\"))\n",
        "    torch.save(aux.state_dict(),  os.path.join(fold_dir, \"aux.pt\"))\n",
        "    scaler.save(os.path.join(fold_dir, \"scaler.pkl\"))\n",
        "    with open(os.path.join(fold_dir, \"meta.json\"), \"w\") as f:\n",
        "        json.dump(meta, f, indent=2)\n",
        "\n",
        "def load_fold(fold_dir, latent_dim=4, c_emb_dim=8):\n",
        "    enc = Encoder(latent_dim=latent_dim).to(DEVICE)\n",
        "    dec = Decoder(latent_dim=latent_dim, c_emb_dim=c_emb_dim).to(DEVICE)\n",
        "    disc = Discriminator(latent_dim=latent_dim).to(DEVICE)\n",
        "    aux = AuxRegressor(latent_dim=latent_dim).to(DEVICE)\n",
        "    enc.load_state_dict(torch.load(os.path.join(fold_dir, \"encoder.pt\"), map_location=DEVICE))\n",
        "    dec.load_state_dict(torch.load(os.path.join(fold_dir, \"decoder.pt\"), map_location=DEVICE))\n",
        "    disc.load_state_dict(torch.load(os.path.join(fold_dir, \"disc.pt\"), map_location=DEVICE))\n",
        "    aux.load_state_dict(torch.load(os.path.join(fold_dir, \"aux.pt\"), map_location=DEVICE))\n",
        "    scaler = SpectraScaler.load(os.path.join(fold_dir, \"scaler.pkl\"))\n",
        "    with open(os.path.join(fold_dir, \"meta.json\"), \"r\") as f:\n",
        "        meta = json.load(f)\n",
        "    cembed = CEmbed(emb_dim=meta[\"c_emb_dim\"]).to(DEVICE)\n",
        "    cembed.load_state_dict(torch.load(os.path.join(fold_dir, \"cembed.pt\"), map_location=DEVICE))\n",
        "    return enc.eval(), dec.eval(), disc.eval(), aux.eval(), cembed.eval(), scaler, meta\n"
      ],
      "metadata": {
        "id": "GF6jOcW0GjZX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Core trainer for one LOCO fold =====\n",
        "def train_fold(fold_spec,\n",
        "               latent_dim=4, c_emb_dim=8, batch_size=32,\n",
        "               max_steps=6000, patience=500,\n",
        "               w_rec=0.9, w_adv=0.1, w_aux=0.05,\n",
        "               lr=4e-4, lr_min=1e-5):\n",
        "\n",
        "    c_hold = float(fold_spec[\"c_hold\"])\n",
        "    train_concs = np.array(fold_spec[\"train_concs\"], dtype=np.float32)\n",
        "    fold_dir = os.path.join(CKPT_ROOT, f\"fold_{int(c_hold)}\")\n",
        "    os.makedirs(fold_dir, exist_ok=True)\n",
        "\n",
        "    # Build training arrays\n",
        "    X_train = np.stack([SPECTRA[c] for c in train_concs], axis=0)  # [5,601]\n",
        "    C_train = np.array([scale_c(c) for c in train_concs], dtype=np.float32).reshape(-1,1)\n",
        "\n",
        "    scaler = SpectraScaler(); scaler.fit(X_train)  # featurewise\n",
        "    Xz = scaler.transform(X_train).astype(np.float32)\n",
        "\n",
        "    # Tiny dataset. We will repeatedly sample minibatches from it.\n",
        "    # Validation proxy will be EMA of training recon loss.\n",
        "    # Models\n",
        "    enc = Encoder(latent_dim=latent_dim).to(DEVICE)\n",
        "    cembed = CEmbed(emb_dim=c_emb_dim).to(DEVICE)\n",
        "    dec = Decoder(latent_dim=latent_dim, c_emb_dim=c_emb_dim).to(DEVICE)\n",
        "    disc = Discriminator(latent_dim=latent_dim).to(DEVICE)\n",
        "    aux = AuxRegressor(latent_dim=latent_dim).to(DEVICE)\n",
        "\n",
        "    # Opts and sched\n",
        "    opt_g = torch.optim.Adam(list(enc.parameters()) + list(dec.parameters()) +\n",
        "                             list(cembed.parameters()) + list(aux.parameters()), lr=lr)\n",
        "    T_max = max_steps\n",
        "    sch_g = torch.optim.lr_scheduler.CosineAnnealingLR(opt_g, T_max=T_max, eta_min=lr_min)\n",
        "\n",
        "    opt_d = torch.optim.Adam(disc.parameters(), lr=lr*0.5)\n",
        "\n",
        "    bce = nn.BCEWithLogitsLoss()\n",
        "    mse = nn.MSELoss()\n",
        "\n",
        "    best_rec = float(\"inf\")\n",
        "    best_step = 0\n",
        "    ema_rec = None\n",
        "    hist = {\"step\": [], \"rec\": [], \"adv\": [], \"aux\": []}\n",
        "\n",
        "    Xnp = Xz.astype(np.float32); Cnp = C_train.astype(np.float32)\n",
        "\n",
        "    for step in range(1, max_steps+1):\n",
        "        # Make a batch by resampling from the 5 rows\n",
        "        xb, cb = make_batch(Xnp, Cnp, batch_size)\n",
        "        z = enc(xb)  # [B,L]\n",
        "        cemb = cembed(cb)  # [B,E]\n",
        "        x_rec = dec(z, cemb)\n",
        "\n",
        "        # --- Discriminator update ---\n",
        "        # Prior samples as \"real\"\n",
        "        z_real = torch.randn_like(z)\n",
        "        logits_real = disc(z_real)\n",
        "        logits_fake = disc(z.detach())\n",
        "        d_loss = bce(logits_real, torch.ones_like(logits_real)) + \\\n",
        "                 bce(logits_fake, torch.zeros_like(logits_fake))\n",
        "        opt_d.zero_grad(set_to_none=True)\n",
        "        d_loss.backward()\n",
        "        opt_d.step()\n",
        "\n",
        "        # --- Generator (E+D+H) update ---\n",
        "        rec = mse(x_rec, xb)\n",
        "        # fool the discriminator\n",
        "        logits_fake2 = disc(z)\n",
        "        adv = bce(logits_fake2, torch.ones_like(logits_fake2))\n",
        "        # auxiliary\n",
        "        c_pred = aux(z)\n",
        "        aux_loss = mse(c_pred, cb)\n",
        "        loss = w_rec*rec + w_adv*adv + w_aux*aux_loss\n",
        "\n",
        "        opt_g.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "        opt_g.step()\n",
        "        sch_g.step()\n",
        "\n",
        "        # Track\n",
        "        rec_val = float(rec.detach().cpu())\n",
        "        ema_rec = rec_val if ema_rec is None else 0.98*ema_rec + 0.02*rec_val\n",
        "        hist[\"step\"].append(step); hist[\"rec\"].append(rec_val)\n",
        "        hist[\"adv\"].append(float(adv.detach().cpu()))\n",
        "        hist[\"aux\"].append(float(aux_loss.detach().cpu()))\n",
        "\n",
        "        # Early stopping on best raw rec\n",
        "        if rec_val < best_rec - 1e-6:\n",
        "            best_rec = rec_val\n",
        "            best_step = step\n",
        "            # Save best so far\n",
        "            torch.save(enc.state_dict(),  os.path.join(fold_dir, \"encoder.pt\"))\n",
        "            torch.save(dec.state_dict(),  os.path.join(fold_dir, \"decoder.pt\"))\n",
        "            torch.save(disc.state_dict(), os.path.join(fold_dir, \"disc.pt\"))\n",
        "            torch.save(aux.state_dict(),  os.path.join(fold_dir, \"aux.pt\"))\n",
        "            torch.save(cembed.state_dict(), os.path.join(fold_dir, \"cembed.pt\"))\n",
        "            scaler.save(os.path.join(fold_dir, \"scaler.pkl\"))\n",
        "            with open(os.path.join(fold_dir, \"train_hist.json\"), \"w\") as f:\n",
        "                json.dump(hist, f)\n",
        "        if step - best_step >= patience:\n",
        "            print(f\"[fold {int(c_hold)}] Early stop at {step}. Best step {best_step} rec {best_rec:.4e}\")\n",
        "            break\n",
        "\n",
        "    # Meta\n",
        "    meta = {\n",
        "        \"c_hold\": float(c_hold),\n",
        "        \"train_concs\": [float(x) for x in train_concs.tolist()],\n",
        "        \"latent_dim\": int(latent_dim),\n",
        "        \"c_emb_dim\": int(c_emb_dim),\n",
        "        \"best_step\": int(best_step),\n",
        "        \"best_rec\": float(best_rec),\n",
        "        \"w_rec\": float(w_rec), \"w_adv\": float(w_adv), \"w_aux\": float(w_aux),\n",
        "        \"lr\": float(lr), \"lr_min\": float(lr_min),\n",
        "        \"max_steps\": int(max_steps), \"patience\": int(patience)\n",
        "    }\n",
        "    with open(os.path.join(fold_dir, \"meta.json\"), \"w\") as f:\n",
        "        json.dump(meta, f, indent=2)\n",
        "\n",
        "    # Return quick info\n",
        "    return {\"fold_dir\": fold_dir, \"meta\": meta, \"best_rec\": best_rec}\n"
      ],
      "metadata": {
        "id": "VsS-wRKyG2ES"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Generation helpers =====\n",
        "def decode_many(dec, cembed, scaler, c_target, N, latent_dim, c_emb_dim):\n",
        "    with torch.no_grad():\n",
        "        z = torch.randn(N, latent_dim, device=DEVICE)\n",
        "        c01 = torch.full((N,1), fill_value=scale_c(c_target), device=DEVICE)\n",
        "        cemb = cembed(c01)\n",
        "        xz = dec(z, cemb)  # standardized\n",
        "        x = scaler.inverse(xz.detach().cpu().numpy())\n",
        "    return x  # [N,601]\n",
        "\n",
        "def filtered_reject(dec, cembed, aux, scaler, c_target, N, latent_dim, eps=0.02, max_trials=20000):\n",
        "    out = []\n",
        "    trials = 0\n",
        "    ct = torch.tensor([[scale_c(c_target)]], device=DEVICE)\n",
        "    while len(out) < N and trials < max_trials:\n",
        "        trials += 256\n",
        "        z = torch.randn(256, latent_dim, device=DEVICE)\n",
        "        c_pred = aux(z)\n",
        "        mask = (c_pred - ct).abs() <= eps\n",
        "        if mask.any():\n",
        "            z_keep = z[mask.squeeze(1)]\n",
        "            with torch.no_grad():\n",
        "                cemb = cembed(ct.repeat(z_keep.size(0),1))\n",
        "                xz = dec(z_keep, cemb)\n",
        "            x = scaler.inverse(xz.detach().cpu().numpy())\n",
        "            out.append(x)\n",
        "    if len(out) == 0:\n",
        "        return np.zeros((0, 601), dtype=np.float32)\n",
        "    X = np.concatenate(out, axis=0)\n",
        "    return X[:N]\n",
        "\n",
        "def filtered_opt(dec, cembed, aux, scaler, c_target, N, latent_dim, steps=200, lr=0.05, lam=0.01, sigma=0.05):\n",
        "    # gradient-based targeting toward c*\n",
        "    X = []\n",
        "    ct = torch.tensor([[scale_c(c_target)]], device=DEVICE)\n",
        "    for _ in range(N):\n",
        "        z = torch.randn(1, latent_dim, device=DEVICE, requires_grad=True)\n",
        "        opt = torch.optim.Adam([z], lr=lr)\n",
        "        for _ in range(steps):\n",
        "            cp = aux(z)\n",
        "            loss = (cp - ct).pow(2).mean() + lam*(z.pow(2).mean())\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "        # small local noise\n",
        "        z_final = z.detach() + sigma*torch.randn_like(z)\n",
        "        with torch.no_grad():\n",
        "            cemb = cembed(ct)\n",
        "            xz = dec(z_final, cemb)\n",
        "        X.append(scaler.inverse(xz.detach().cpu().numpy()))\n",
        "    return np.concatenate(X, axis=0)\n",
        "\n",
        "# ===== Public API =====\n",
        "_LAST_FOLD_CACHE = {}  # c_hold -> loaded modules\n",
        "\n",
        "def _pick_fold_for_c(c_target):\n",
        "    # Choose fold that held the nearest concentration to c_target\n",
        "    diffs = {float(c): abs(c_target - float(c)) for c in concs_all}\n",
        "    nearest = min(diffs, key=diffs.get)\n",
        "    return int(nearest)\n",
        "\n",
        "def _load_fold_cached(c_hold):\n",
        "    if c_hold in _LAST_FOLD_CACHE:\n",
        "        return _LAST_FOLD_CACHE[c_hold]\n",
        "    fold_dir = os.path.join(CKPT_ROOT, f\"fold_{int(c_hold)}\")\n",
        "    enc, dec, disc, aux, cemb, scaler, meta = load_fold(fold_dir)\n",
        "    _LAST_FOLD_CACHE[c_hold] = (enc, dec, disc, aux, cemb, scaler, meta)\n",
        "    return _LAST_FOLD_CACHE[c_hold]\n",
        "\n",
        "def generate_spectra(c_target, N=64, mode=\"conditional\"):\n",
        "    \"\"\"Returns np.ndarray [N,601] in baseline-corrected absorbance space.\"\"\"\n",
        "    fold_to_use = _pick_fold_for_c(c_target)\n",
        "    enc, dec, disc, aux, cemb, scaler, meta = _load_fold_cached(fold_to_use)\n",
        "    latent_dim = meta[\"latent_dim\"]; c_emb_dim = meta[\"c_emb_dim\"]\n",
        "\n",
        "    if mode == \"conditional\":\n",
        "        X = decode_many(dec, cemb, scaler, c_target, N, latent_dim, c_emb_dim)\n",
        "    elif mode == \"filtered_reject\":\n",
        "        X = filtered_reject(dec, cemb, aux, scaler, c_target, N, latent_dim, eps=0.02)\n",
        "    elif mode == \"filtered_opt\":\n",
        "        X = filtered_opt(dec, cemb, aux, scaler, c_target, N, latent_dim, steps=200, lr=0.05, lam=0.01, sigma=0.05)\n",
        "    else:\n",
        "        raise ValueError(\"mode must be one of {'conditional','filtered_reject','filtered_opt'}\")\n",
        "    # Save optional dump\n",
        "    np.save(os.path.join(GEN_ROOT, f\"gen_c_{int(round(c_target))}_{mode}.npy\"), X.astype(np.float32))\n",
        "    return X\n"
      ],
      "metadata": {
        "id": "tdFeifgeGm3y"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_loco(N=64, modes=(\"conditional\",\"filtered_opt\")):\n",
        "    rows = []\n",
        "    for c_hold, train_concs in split_loco(concs_all):\n",
        "        # train this fold if not already present\n",
        "        fold_dir = os.path.join(CKPT_ROOT, f\"fold_{int(c_hold)}\")\n",
        "        if not os.path.exists(os.path.join(fold_dir, \"encoder.pt\")):\n",
        "            print(f\"Training fold for held {int(c_hold)}\")\n",
        "            train_fold({\"c_hold\": float(c_hold), \"train_concs\": train_concs})\n",
        "        # load trained\n",
        "        enc, dec, disc, aux, cemb, scaler, meta = load_fold(fold_dir)\n",
        "        latent_dim = meta[\"latent_dim\"]; c_emb_dim = meta[\"c_emb_dim\"]\n",
        "\n",
        "        # Real held spectrum in baseline-corrected space with same scaler\n",
        "        x_true = SPECTRA[float(c_hold)]\n",
        "        # for baseline comparison we build linear interpolation from training concs and spectra\n",
        "        A_train_mat = np.stack([SPECTRA[float(c)] for c in train_concs], axis=1)\n",
        "        lin_pred = linear_baseline_interp(train_concs, A_train_mat, float(c_hold))\n",
        "\n",
        "        # For metrics, we compare mean generated spectrum to real held\n",
        "        for mode in modes:\n",
        "            if mode == \"conditional\":\n",
        "                X = decode_many(dec, cemb, scaler, float(c_hold), N, latent_dim, c_emb_dim)\n",
        "            elif mode == \"filtered_opt\":\n",
        "                X = filtered_opt(dec, cemb, aux, scaler, float(c_hold), N, latent_dim, steps=200, lr=0.05, lam=0.01, sigma=0.05)\n",
        "            elif mode == \"filtered_reject\":\n",
        "                X = filtered_reject(dec, cemb, aux, scaler, float(c_hold), N, latent_dim, eps=0.02)\n",
        "            else:\n",
        "                continue\n",
        "            x_mean = X.mean(axis=0)\n",
        "\n",
        "            r = pearsonr(x_true, x_mean)\n",
        "            e = rmse(x_true, x_mean)\n",
        "            p_err = abs(peak_nm(wl, x_true) - peak_nm(wl, x_mean))\n",
        "\n",
        "            # linear baseline metrics\n",
        "            e_lin = rmse(x_true, lin_pred)\n",
        "            r_lin = pearsonr(x_true, lin_pred)\n",
        "\n",
        "            rows.append({\n",
        "                \"c_hold\": float(c_hold),\n",
        "                \"mode\": mode,\n",
        "                \"rmse\": e,\n",
        "                \"pearson_r\": r,\n",
        "                \"peak_shift_nm\": p_err,\n",
        "                \"rmse_linear\": e_lin,\n",
        "                \"pearson_r_linear\": r_lin\n",
        "            })\n",
        "\n",
        "            # Plot overlay and uncertainty band\n",
        "            fig = plt.figure(figsize=(8,4))\n",
        "            plt.plot(wl, x_true, label=f\"Real c={int(c_hold)}\")\n",
        "            plt.plot(wl, x_mean, label=f\"AAE mean {mode}\")\n",
        "            # uncertainty band\n",
        "            std = X.std(axis=0)\n",
        "            plt.fill_between(wl, x_mean-std, x_mean+std, alpha=0.2, label=\"AAE Â±1 sd\")\n",
        "            # linear baseline\n",
        "            plt.plot(wl, lin_pred, linestyle=\":\", label=\"Linear baseline\")\n",
        "            plt.xlabel(\"Wavelength (nm)\"); plt.ylabel(\"Absorbance (baseline corrected)\")\n",
        "            plt.legend(loc=\"best\")\n",
        "            plt.tight_layout()\n",
        "            outpng = os.path.join(FIG_ROOT, f\"loco_c_{int(c_hold)}_{mode}.png\")\n",
        "            plt.savefig(outpng, dpi=160); plt.close(fig)\n",
        "\n",
        "        # Save a CSV of generated mean spectra for this held concentration\n",
        "        out_csv = os.path.join(GEN_ROOT, f\"loco_c_{int(c_hold)}.csv\")\n",
        "        cols = {}\n",
        "        for mode in modes:\n",
        "            # regenerate to avoid storing large arrays\n",
        "            if mode == \"conditional\":\n",
        "                X = decode_many(dec, cemb, scaler, float(c_hold), N, latent_dim, c_emb_dim)\n",
        "            else:\n",
        "                X = filtered_opt(dec, cemb, aux, scaler, float(c_hold), N, latent_dim)\n",
        "            cols[f\"gen_mean_{mode}\"] = X.mean(axis=0)\n",
        "        df = pd.DataFrame({\"Wavelength\": wl, \"Real\": x_true, \"Linear\": lin_pred, **cols})\n",
        "        df.to_csv(out_csv, index=False)\n",
        "\n",
        "    dfres = pd.DataFrame(rows)\n",
        "    dfres_path = os.path.join(ROOT, \"loco_results.csv\")\n",
        "    dfres.to_csv(dfres_path, index=False)\n",
        "    print(\"Saved LOCO results to\", dfres_path)\n",
        "    return dfres\n",
        "\n",
        "def generate_grid(c_values, N_per=32, mode=\"conditional\"):\n",
        "    out = {}\n",
        "    rows = []\n",
        "    for c in c_values:\n",
        "        X = generate_spectra(c, N=N_per, mode=mode)\n",
        "        out[c] = X\n",
        "        rows.append(np.concatenate([[c], X.mean(axis=0)], axis=0))\n",
        "    grid = np.stack(rows, axis=0)\n",
        "    cols = [\"c\"] + [f\"{int(w)}\" for w in wl]\n",
        "    df = pd.DataFrame(grid, columns=cols)\n",
        "    csv_path = os.path.join(GEN_ROOT, \"gen_grid_interp.csv\")\n",
        "    df.to_csv(csv_path, index=False)\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "1NObpzyPG4Tp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Train all folds and print LOCO table =====\n",
        "metrics = evaluate_loco()   # trains missing folds, evaluates modes: conditional and filtered_opt\n",
        "print(metrics)\n",
        "\n",
        "# ===== Interpolate at c*=25 using conditional decoding =====\n",
        "specs = generate_spectra(25.0, N=64, mode=\"conditional\")\n",
        "print(\"Generated specs shape:\", specs.shape)\n",
        "\n",
        "# ===== Same using filtered optimization =====\n",
        "specs_opt = generate_spectra(25.0, N=64, mode=\"filtered_opt\")\n",
        "print(\"Generated specs_opt shape:\", specs_opt.shape)\n",
        "\n",
        "# ===== Smoothness diagnostic across midpoints =====\n",
        "midpoints = [5, 15, 25, 35, 50]\n",
        "grid = generate_grid(midpoints, N_per=32, mode=\"conditional\")\n",
        "\n",
        "# Simple smoothness score by total variation across concentrations\n",
        "means = np.stack([grid[c].mean(axis=0) for c in midpoints], axis=0)  # [M,601]\n",
        "tv = np.abs(np.diff(means, axis=0)).sum()  # scalar\n",
        "print(\"Total variation across c midpoints:\", float(tv))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCkipUX7G6h9",
        "outputId": "f27c9d9d-aaf7-408a-b7a1-92dba5ac3410"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training fold for held 0\n",
            "[fold 0] Early stop at 1983. Best step 1483 rec 2.2747e-05\n",
            "Training fold for held 10\n",
            "[fold 10] Early stop at 1395. Best step 895 rec 3.2301e-05\n",
            "Training fold for held 20\n",
            "[fold 20] Early stop at 1006. Best step 506 rec 1.7088e-05\n",
            "Training fold for held 30\n",
            "[fold 30] Early stop at 1117. Best step 617 rec 1.6933e-05\n",
            "Training fold for held 40\n",
            "[fold 40] Early stop at 1725. Best step 1225 rec 2.4530e-05\n",
            "Training fold for held 60\n",
            "[fold 60] Early stop at 1378. Best step 878 rec 6.8582e-05\n",
            "Saved LOCO results to /content/drive/MyDrive/ArsenicSTS/loco_results.csv\n",
            "    c_hold          mode      rmse  pearson_r  peak_shift_nm  rmse_linear  \\\n",
            "0      0.0   conditional  0.013299   0.955343            0.0     0.041023   \n",
            "1      0.0  filtered_opt  0.027287   0.868159            0.0     0.041023   \n",
            "2     10.0   conditional  0.013565   0.979066            0.0     0.020511   \n",
            "3     10.0  filtered_opt  0.003823   0.991086            0.0     0.020511   \n",
            "4     20.0   conditional  0.028519   0.922022            0.0     0.022528   \n",
            "5     20.0  filtered_opt  0.038024   0.864338            0.0     0.022528   \n",
            "6     30.0   conditional  0.020868   0.947165            0.0     0.001483   \n",
            "7     30.0  filtered_opt  0.028879   0.900559            0.0     0.001483   \n",
            "8     40.0   conditional  0.014222   0.947457            0.0     0.004000   \n",
            "9     40.0  filtered_opt  0.016030   0.933892            0.0     0.004000   \n",
            "10    60.0   conditional  0.020936   0.944056            0.0     0.012000   \n",
            "11    60.0  filtered_opt  0.026877   0.894253            0.0     0.012000   \n",
            "\n",
            "    pearson_r_linear  \n",
            "0           0.869412  \n",
            "1           0.869412  \n",
            "2           0.956306  \n",
            "3           0.956306  \n",
            "4           0.957343  \n",
            "5           0.957343  \n",
            "6           0.998602  \n",
            "7           0.998602  \n",
            "8           0.992794  \n",
            "9           0.992794  \n",
            "10          0.946075  \n",
            "11          0.946075  \n",
            "Generated specs shape: (64, 601)\n",
            "Generated specs_opt shape: (64, 601)\n",
            "Total variation across c midpoints: 9.065722465515137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MLP"
      ],
      "metadata": {
        "id": "YAbyDlrReRYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Setup ===\n",
        "# If in Colab, mount Drive first:\n",
        "# from google.colab import drive; drive.mount('/content/drive')\n",
        "\n",
        "import os, math, json, time, random, pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "SEED = 1337\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Paths\n",
        "ROOT = \"/content/drive/MyDrive/ArsenicSTS\"\n",
        "DATA_CSV = f\"{ROOT}/UVVisData/0.30MB_AuNP_As.csv\"\n",
        "OUT_ROOT  = f\"{ROOT}/coordnet_ckpts\"\n",
        "FIG_ROOT  = f\"{ROOT}/figs_coordnet\"\n",
        "os.makedirs(OUT_ROOT, exist_ok=True)\n",
        "os.makedirs(FIG_ROOT, exist_ok=True)\n",
        "\n",
        "# === Data loading ===\n",
        "def load_uvvis_csv(path, baseline_correct=True):\n",
        "    df = pd.read_csv(path)\n",
        "    df.columns = [str(c).strip() for c in df.columns]\n",
        "    assert \"Wavelength\" in df.columns\n",
        "    wl = df[\"Wavelength\"].to_numpy().astype(np.float32)\n",
        "    conc_cols = []\n",
        "    for c in df.columns:\n",
        "        if c == \"Wavelength\": continue\n",
        "        try: float(c); conc_cols.append(c)\n",
        "        except: pass\n",
        "    conc_vals = np.array(sorted([float(c) for c in conc_cols], key=float), dtype=np.float32)\n",
        "    cols_sorted = [str(int(c)) if float(c).is_integer() else str(c) for c in conc_vals]\n",
        "    A = np.stack([df[c].to_numpy().astype(np.float32) for c in cols_sorted], axis=1)  # [601,6]\n",
        "    if baseline_correct:\n",
        "        idx_800 = int(np.argmin(np.abs(wl - 800.0)))\n",
        "        A = A - A[idx_800:idx_800+1, :]\n",
        "    return wl, conc_vals, A  # [W], [K], [W,K]\n",
        "\n",
        "wl, concs_all, A_mat = load_uvvis_csv(DATA_CSV, baseline_correct=True)\n",
        "WMIN, WMAX = float(wl.min()), float(wl.max())\n",
        "CMIN, CMAX = float(concs_all.min()), float(concs_all.max())\n",
        "\n",
        "def scale01(x, lo, hi): return (x - lo) / (hi - lo + 1e-12)\n",
        "def unscale01(y, lo, hi): return y*(hi-lo) + lo\n",
        "\n",
        "# Pair grid\n",
        "# Pairs (w, c) -> A\n",
        "def make_pair_grid(wl, concs, A):\n",
        "    W, K = A.shape\n",
        "    ww = np.repeat(wl.reshape(W,1), K, axis=1)\n",
        "    cc = np.repeat(concs.reshape(1,K), W, axis=0)\n",
        "    y  = A.copy()\n",
        "    return ww.astype(np.float32), cc.astype(np.float32), y.astype(np.float32)\n",
        "\n",
        "# Simple baseline: linear in concentration per wavelength\n",
        "def linear_interp_at_c(train_concs, A_train, c_target):\n",
        "    concs = np.array(train_concs, dtype=np.float32)\n",
        "    Akn = np.array(A_train, dtype=np.float32)  # [W,K]\n",
        "    if c_target <= concs.min(): i0,i1 = 0,1\n",
        "    elif c_target >= concs.max(): i0,i1 = len(concs)-2, len(concs)-1\n",
        "    else:\n",
        "        i1 = int(np.searchsorted(concs, c_target, side=\"right\")); i0 = i1 - 1\n",
        "    c0, c1 = concs[i0], concs[i1]\n",
        "    w = (c_target - c0) / (c1 - c0 + 1e-12)\n",
        "    return (1 - w) * Akn[:, i0] + w * Akn[:, i1]\n",
        "\n",
        "# Metrics\n",
        "def rmse(a,b): return float(np.sqrt(np.mean((a-b)**2)))\n",
        "def pearsonr(a,b):\n",
        "    a=a-a.mean(); b=b-b.mean()\n",
        "    den = np.sqrt((a*a).sum()) * np.sqrt((b*b).sum()) + 1e-12\n",
        "    return float((a*b).sum()/den)\n",
        "def peak_nm(wl, spec): return float(wl[int(np.argmax(spec))])\n",
        "\n",
        "# === Fourier features and model ===\n",
        "class FourierEmbed(nn.Module):\n",
        "    def __init__(self, n_freq, max_freq_log2=8):\n",
        "        super().__init__()\n",
        "        # Frequencies: 2^k, k in [0..max_log], then 2*pi\n",
        "        k = torch.linspace(0, max_freq_log2, steps=n_freq)\n",
        "        self.register_buffer(\"freq\", (2.0**k)*math.pi*2.0)  # [n_freq]\n",
        "    def forward(self, x01):\n",
        "        # x01 shape [N,1] in [0,1]\n",
        "        x = x01 * self.freq  # [N,nf]\n",
        "        return torch.cat([torch.sin(x), torch.cos(x), x01], dim=-1)\n",
        "\n",
        "class CoordNet(nn.Module):\n",
        "    def __init__(self, nfw=8, nfc=4, hidden=256, depth=4):\n",
        "        super().__init__()\n",
        "        self.emb_w = FourierEmbed(nfw)\n",
        "        self.emb_c = FourierEmbed(nfc)\n",
        "        in_dim = (2*nfw+1) + (2*nfc+1)\n",
        "        layers = []\n",
        "        dims = [in_dim] + [hidden]*depth + [1]\n",
        "        for i in range(len(dims)-2):\n",
        "            layers += [nn.Linear(dims[i], dims[i+1]), nn.LayerNorm(dims[i+1]), nn.SiLU()]\n",
        "        layers += [nn.Linear(dims[-2], dims[-1])]\n",
        "        self.f = nn.Sequential(*layers)\n",
        "    def forward(self, w01, c01):\n",
        "        phi = torch.cat([self.emb_w(w01), self.emb_c(c01)], dim=-1)\n",
        "        return self.f(phi)  # [N,1]\n",
        "\n",
        "# Target scaler\n",
        "class ScalarStd:\n",
        "    def __init__(self): self.m=None; self.s=None\n",
        "    def fit(self, y): y=np.asarray(y).reshape(-1); self.m=float(y.mean()); self.s=float(y.std()+1e-6)\n",
        "    def transform(self, y): return (y - self.m)/self.s\n",
        "    def inverse(self, y): return y*self.s + self.m\n",
        "\n",
        "# Mini helpers\n",
        "def softargmax_coords(values, coords, tau=8.0):\n",
        "    # values [W], coords [W]\n",
        "    v = torch.tensor(values, dtype=torch.float32, device=DEVICE).view(1,-1)\n",
        "    x = torch.tensor(coords, dtype=torch.float32, device=DEVICE).view(1,-1)\n",
        "    w = F.softmax(v/tau, dim=1)\n",
        "    mu = (w*x).sum(dim=1)  # [1]\n",
        "    return mu.squeeze(0)\n",
        "\n",
        "def spectrum_losses(model, c_list, wl, y_mat_true, scaler, tau=8.0):\n",
        "    # c_list in original units, wl in nm, y_mat_true baseline corrected [W,K_train]\n",
        "    W = len(wl)\n",
        "    losses_cos = []\n",
        "    losses_peak = []\n",
        "    for c in c_list:\n",
        "        w01 = torch.from_numpy(scale01(wl, WMIN, WMAX).reshape(-1,1)).float().to(DEVICE)\n",
        "        c01 = torch.full((W,1), fill_value=scale01(c, CMIN, CMAX), device=DEVICE)\n",
        "        with torch.no_grad():\n",
        "            yhat_z = model(w01.requires_grad_(False), c01.requires_grad_(False)).squeeze(1)  # scaled\n",
        "        yhat = scaler.inverse(yhat_z.detach().cpu().numpy())\n",
        "        # true spectrum\n",
        "        # find index of c in training concs map in outer scope when calling\n",
        "        # Here caller passes the right y_mat_true for train concs ordered same as c_list if needed\n",
        "        ytrue = y_mat_true[c]  # dict mapping float c -> [W]\n",
        "        # cosine alignment\n",
        "        a = torch.tensor(yhat, device=DEVICE).view(1,-1)\n",
        "        b = torch.tensor(ytrue, device=DEVICE).view(1,-1)\n",
        "        cos = 1.0 - F.cosine_similarity(a, b).mean()\n",
        "        # peak center\n",
        "        mu_hat = softargmax_coords(yhat, wl, tau=tau)\n",
        "        mu_true = softargmax_coords(ytrue, wl, tau=tau)\n",
        "        peak_err = torch.abs(mu_hat - mu_true) / (WMAX - WMIN)  # normalized nm\n",
        "        losses_cos.append(cos)\n",
        "        losses_peak.append(peak_err)\n",
        "    if len(losses_cos)==0:\n",
        "        return torch.tensor(0.0, device=DEVICE), torch.tensor(0.0, device=DEVICE)\n",
        "    return torch.stack(losses_cos).mean(), torch.stack(losses_peak).mean()\n",
        "\n",
        "# === Fold training ===\n",
        "def train_loco_fold(c_hold,\n",
        "                    max_steps=8000,\n",
        "                    batch_size=4096,\n",
        "                    lr=3e-3,\n",
        "                    lr_min=3e-5,\n",
        "                    nfw=10,\n",
        "                    nfc=6,\n",
        "                    hidden=256,\n",
        "                    depth=4,\n",
        "                    lam_w=1e-2,\n",
        "                    lam_c=1e-2,\n",
        "                    lam_cos=1e-2,\n",
        "                    lam_peak=5e-3,\n",
        "                    spec_loss_every=100,\n",
        "                    spec_loss_K=2,\n",
        "                    verbose=True):\n",
        "    # Build grids\n",
        "    ww, cc, yy = make_pair_grid(wl, concs_all, A_mat)  # [W,K]\n",
        "    K_all = list(map(float, concs_all.tolist()))\n",
        "    K_train = [float(c) for c in K_all if float(c) != float(c_hold)]\n",
        "    K_hold  = float(c_hold)\n",
        "\n",
        "    # Training pairs\n",
        "    mask = np.isin(cc, np.array(K_train)[None,:]).astype(np.bool_)\n",
        "    w_train = ww[mask]\n",
        "    c_train = cc[mask]\n",
        "    y_train = yy[mask]\n",
        "\n",
        "    # Validation split from training pairs\n",
        "    N = w_train.shape[0]\n",
        "    idx = np.arange(N)\n",
        "    np.random.shuffle(idx)\n",
        "    n_val = max(256, int(0.1*N))\n",
        "    val_idx = idx[:n_val]\n",
        "    tr_idx  = idx[n_val:]\n",
        "    w_tr, c_tr, y_tr = w_train[tr_idx], c_train[tr_idx], y_train[tr_idx]\n",
        "    w_vl, c_vl, y_vl = w_train[val_idx], c_train[val_idx], y_train[val_idx]\n",
        "\n",
        "    # Target scaler fit on training targets\n",
        "    scaler = ScalarStd(); scaler.fit(y_tr)\n",
        "    y_tr_z = scaler.transform(y_tr).astype(np.float32)\n",
        "    y_vl_z = scaler.transform(y_vl).astype(np.float32)\n",
        "\n",
        "    # Dict of true spectra for spectrum-level losses\n",
        "    train_spec_dict = {float(c): A_mat[:, list(K_all).index(c)] for c in K_train}\n",
        "\n",
        "    # Model, opt, sched\n",
        "    model = CoordNet(nfw=nfw, nfc=nfc, hidden=hidden, depth=depth).to(DEVICE)\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-6)\n",
        "    sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=max_steps, eta_min=lr_min)\n",
        "\n",
        "    best_vl = float(\"inf\"); best_state = None; best_step = 0\n",
        "    ema = None\n",
        "\n",
        "    for step in range(1, max_steps+1):\n",
        "        # Batch sample with replacement\n",
        "        sel = np.random.randint(0, w_tr.shape[0], size=(batch_size,))\n",
        "        w_b = torch.from_numpy(scale01(w_tr[sel], WMIN, WMAX)).float().to(DEVICE).view(-1,1).requires_grad_(True)\n",
        "        c_b = torch.from_numpy(scale01(c_tr[sel], CMIN, CMAX)).float().to(DEVICE).view(-1,1).requires_grad_(True)\n",
        "        y_b = torch.from_numpy(y_tr_z[sel]).float().to(DEVICE).view(-1,1)\n",
        "\n",
        "        y_hat = model(w_b, c_b)\n",
        "        l_rec = F.mse_loss(y_hat, y_b)\n",
        "\n",
        "        # Smoothness penalties via grads\n",
        "        ones = torch.ones_like(y_hat)\n",
        "        dA_dw = torch.autograd.grad(y_hat, w_b, grad_outputs=ones, create_graph=True, retain_graph=True)[0]\n",
        "        dA_dc = torch.autograd.grad(y_hat, c_b, grad_outputs=ones, create_graph=True, retain_graph=True)[0]\n",
        "        l_smooth = lam_w * (dA_dw.pow(2).mean()) + lam_c * (dA_dc.pow(2).mean())\n",
        "\n",
        "        # Spectrum-level losses occasionally\n",
        "        l_cos = torch.tensor(0.0, device=DEVICE)\n",
        "        l_peak = torch.tensor(0.0, device=DEVICE)\n",
        "        if spec_loss_every > 0 and step % spec_loss_every == 0:\n",
        "            pick = np.random.choice(K_train, size=min(spec_loss_K, len(K_train)), replace=False)\n",
        "            l_cos, l_peak = spectrum_losses(model, pick, wl, train_spec_dict, scaler, tau=8.0)\n",
        "            l_cos = lam_cos * l_cos\n",
        "            l_peak= lam_peak * l_peak\n",
        "\n",
        "        loss = l_rec + l_smooth + l_cos + l_peak\n",
        "        opt.zero_grad(set_to_none=True); loss.backward(); opt.step(); sched.step()\n",
        "\n",
        "        # Small validation\n",
        "        with torch.no_grad():\n",
        "            wv = torch.from_numpy(scale01(w_vl, WMIN, WMAX)).float().to(DEVICE).view(-1,1)\n",
        "            cv = torch.from_numpy(scale01(c_vl, CMIN, CMAX)).float().to(DEVICE).view(-1,1)\n",
        "            yv = torch.from_numpy(y_vl_z).float().to(DEVICE).view(-1,1)\n",
        "            yh = model(wv, cv)\n",
        "            vl = F.mse_loss(yh, yv).item()\n",
        "            ema = vl if ema is None else 0.98*ema + 0.02*vl\n",
        "\n",
        "        if vl < best_vl - 1e-6:\n",
        "            best_vl = vl; best_step = step\n",
        "            best_state = {k: v.detach().cpu().clone() for k,v in model.state_dict().items()}\n",
        "\n",
        "        if verbose and step % 200 == 0:\n",
        "            print(f\"[hold {int(c_hold)}] step {step}  rec {l_rec.item():.4e}  vl {vl:.4e}  ema {ema:.4e}\")\n",
        "\n",
        "        if step - best_step >= 1000:\n",
        "            if verbose: print(f\"[hold {int(c_hold)}] early stop at {step}, best {best_step}\")\n",
        "            break\n",
        "\n",
        "    # Save best\n",
        "    fold_dir = os.path.join(OUT_ROOT, f\"fold_{int(c_hold)}\"); os.makedirs(fold_dir, exist_ok=True)\n",
        "    torch.save(best_state, os.path.join(fold_dir, \"coordnet.pt\"))\n",
        "    with open(os.path.join(fold_dir, \"scaler.pkl\"), \"wb\") as f: pickle.dump({\"m\": scaler.m, \"s\": scaler.s}, f)\n",
        "    meta = {\"c_hold\": float(c_hold), \"train_concs\": [float(x) for x in K_train],\n",
        "            \"WMIN\": WMIN, \"WMAX\": WMAX, \"CMIN\": CMIN, \"CMAX\": CMAX,\n",
        "            \"nfw\": nfw, \"nfc\": nfc, \"hidden\": hidden, \"depth\": depth,\n",
        "            \"best_step\": int(best_step), \"best_vl\": float(best_vl)}\n",
        "    with open(os.path.join(fold_dir, \"meta.json\"), \"w\") as f: json.dump(meta, f, indent=2)\n",
        "    return fold_dir\n",
        "\n",
        "def load_fold(fold_dir):\n",
        "    with open(os.path.join(fold_dir, \"meta.json\"), \"r\") as f: meta = json.load(f)\n",
        "    model = CoordNet(nfw=meta[\"nfw\"], nfc=meta[\"nfc\"], hidden=meta[\"hidden\"], depth=meta[\"depth\"]).to(DEVICE)\n",
        "    state = torch.load(os.path.join(fold_dir, \"coordnet.pt\"), map_location=DEVICE)\n",
        "    model.load_state_dict(state); model.eval()\n",
        "    with open(os.path.join(fold_dir, \"scaler.pkl\"), \"rb\") as f: d=pickle.load(f)\n",
        "    scaler = ScalarStd(); scaler.m = d[\"m\"]; scaler.s = d[\"s\"]\n",
        "    return model, scaler, meta\n",
        "\n",
        "def predict_spectrum(model, scaler, c_target):\n",
        "    W = len(wl)\n",
        "    w01 = torch.from_numpy(scale01(wl, WMIN, WMAX).reshape(-1,1)).float().to(DEVICE)\n",
        "    c01 = torch.full((W,1), fill_value=scale01(c_target, CMIN, CMAX), device=DEVICE)\n",
        "    with torch.no_grad():\n",
        "        y_z = model(w01, c01).squeeze(1).cpu().numpy()\n",
        "    y = scaler.inverse(y_z)\n",
        "    return y  # baseline corrected absorbance\n",
        "\n",
        "# === LOCO evaluation ===\n",
        "def evaluate_loco(max_steps=8000):\n",
        "    rows = []\n",
        "    # make a plain Python list of floats once\n",
        "    concs_list = [float(x) for x in (concs_all.tolist() if hasattr(concs_all, \"tolist\") else list(concs_all))]\n",
        "\n",
        "    for c_hold in concs_all:\n",
        "        fold_dir = os.path.join(OUT_ROOT, f\"fold_{int(c_hold)}\")\n",
        "        if not os.path.exists(os.path.join(fold_dir, \"coordnet.pt\")):\n",
        "            print(f\"Training fold hold {int(c_hold)}\")\n",
        "            train_loco_fold(float(c_hold), max_steps=max_steps)\n",
        "        model, scaler, meta = load_fold(fold_dir)\n",
        "\n",
        "        # True held spectrum\n",
        "        idx_hold = concs_list.index(float(c_hold))\n",
        "        A_true = A_mat[:, idx_hold]\n",
        "\n",
        "        # Linear baseline from train concs\n",
        "        A_train_mat = np.stack([A_mat[:, concs_list.index(float(c))] for c in meta[\"train_concs\"]], axis=1)\n",
        "        A_lin = linear_interp_at_c(meta[\"train_concs\"], A_train_mat, float(c_hold))\n",
        "\n",
        "        # Model prediction\n",
        "        A_pred = predict_spectrum(model, scaler, float(c_hold))\n",
        "\n",
        "        r  = pearsonr(A_true, A_pred)\n",
        "        e  = rmse(A_true, A_pred)\n",
        "        ps = abs(peak_nm(wl, A_true) - peak_nm(wl, A_pred))\n",
        "        e_lin  = rmse(A_true, A_lin)\n",
        "        r_lin  = pearsonr(A_true, A_lin)\n",
        "\n",
        "        rows.append({\"c_hold\": float(c_hold), \"rmse\": e, \"pearson_r\": r, \"peak_shift_nm\": ps,\n",
        "                     \"rmse_linear\": e_lin, \"pearson_r_linear\": r_lin})\n",
        "\n",
        "        # Plot\n",
        "        fig = plt.figure(figsize=(8,4))\n",
        "        plt.plot(wl, A_true, label=f\"Real c={int(c_hold)}\")\n",
        "        plt.plot(wl, A_pred, label=\"CoordNet\")\n",
        "        plt.plot(wl, A_lin, linestyle=\":\", label=\"Linear\")\n",
        "        plt.xlabel(\"Wavelength (nm)\"); plt.ylabel(\"Absorbance (baseline corrected)\")\n",
        "        plt.legend(); plt.tight_layout()\n",
        "        outpng = os.path.join(FIG_ROOT, f\"coordnet_loco_{int(c_hold)}.png\")\n",
        "        plt.savefig(outpng, dpi=160); plt.close(fig)\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "    csv_path = os.path.join(OUT_ROOT, \"loco_results_coordnet.csv\")\n",
        "    df.to_csv(csv_path, index=False)\n",
        "    print(\"Saved LOCO results to\", csv_path)\n",
        "    return df\n",
        "\n",
        "# === Run ===\n",
        "# Train folds and report metrics\n",
        "df_res = evaluate_loco(max_steps=8000)\n",
        "print(df_res)\n",
        "\n",
        "# Example: predict at c* = 25\n",
        "# Pick the fold whose hold is closest to 25 for a fair decoder choice\n",
        "nearest = float(min(concs_all, key=lambda c: abs(c-25)))\n",
        "fold_dir = os.path.join(OUT_ROOT, f\"fold_{int(nearest)}\")\n",
        "model, scaler, meta = load_fold(fold_dir)\n",
        "A_25 = predict_spectrum(model, scaler, 25.0)\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.plot(wl, A_25, label=\"Pred c=25\")\n",
        "plt.xlabel(\"Wavelength (nm)\"); plt.ylabel(\"Absorbance (baseline corrected)\")\n",
        "plt.legend(); plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0weDRSjBdzcZ",
        "outputId": "09d190d9-68e2-48ff-c1dc-a6302ef930b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training fold hold 10\n",
            "[hold 10] step 200  rec 9.8360e-01  vl 1.0993e+00  ema 1.1081e+00\n",
            "[hold 10] step 400  rec 1.0065e+00  vl 1.0974e+00  ema 1.0977e+00\n",
            "[hold 10] step 600  rec 9.4386e-01  vl 1.0960e+00  ema 1.0960e+00\n",
            "[hold 10] step 800  rec 9.7790e-01  vl 1.0942e+00  ema 1.0949e+00\n",
            "[hold 10] step 1000  rec 1.0323e+00  vl 1.0925e+00  ema 1.0931e+00\n",
            "[hold 10] early stop at 1004, best 4\n",
            "Training fold hold 20\n",
            "[hold 20] step 200  rec 9.3741e-01  vl 8.6643e-01  ema 8.7686e-01\n",
            "[hold 20] step 400  rec 8.3752e-01  vl 8.6532e-01  ema 8.6594e-01\n",
            "[hold 20] step 600  rec 9.9406e-01  vl 8.6530e-01  ema 8.6523e-01\n",
            "[hold 20] step 800  rec 9.9973e-01  vl 8.6371e-01  ema 8.6401e-01\n",
            "[hold 20] step 1000  rec 1.0118e+00  vl 8.6307e-01  ema 8.6323e-01\n",
            "[hold 20] early stop at 1016, best 16\n",
            "Training fold hold 30\n",
            "[hold 30] step 200  rec 1.0450e+00  vl 9.4627e-01  ema 9.5027e-01\n",
            "[hold 30] step 400  rec 9.5441e-01  vl 9.4672e-01  ema 9.4669e-01\n",
            "[hold 30] step 600  rec 9.9826e-01  vl 9.4714e-01  ema 9.4631e-01\n",
            "[hold 30] step 800  rec 9.7112e-01  vl 9.4585e-01  ema 9.4580e-01\n",
            "[hold 30] step 1000  rec 1.0517e+00  vl 9.4387e-01  ema 9.4435e-01\n",
            "[hold 30] early stop at 1011, best 11\n",
            "Training fold hold 40\n",
            "[hold 40] step 200  rec 1.0377e+00  vl 1.1963e+00  ema 1.2008e+00\n",
            "[hold 40] step 400  rec 9.8104e-01  vl 1.1953e+00  ema 1.1955e+00\n",
            "[hold 40] step 600  rec 1.0597e+00  vl 1.1945e+00  ema 1.1947e+00\n",
            "[hold 40] step 800  rec 1.0071e+00  vl 1.1934e+00  ema 1.1937e+00\n",
            "[hold 40] step 1000  rec 9.7666e-01  vl 1.1928e+00  ema 1.1929e+00\n",
            "[hold 40] early stop at 1006, best 6\n",
            "Training fold hold 60\n",
            "[hold 60] step 200  rec 1.0323e+00  vl 1.3088e+00  ema 1.3180e+00\n",
            "[hold 60] step 400  rec 9.9829e-01  vl 1.3053e+00  ema 1.3062e+00\n",
            "[hold 60] step 600  rec 1.0125e+00  vl 1.3027e+00  ema 1.3032e+00\n",
            "[hold 60] step 800  rec 9.4698e-01  vl 1.2999e+00  ema 1.3007e+00\n",
            "[hold 60] step 1000  rec 9.6989e-01  vl 1.2978e+00  ema 1.2984e+00\n",
            "[hold 60] step 1200  rec 9.7339e-01  vl 1.2957e+00  ema 1.2961e+00\n",
            "[hold 60] step 1400  rec 9.7569e-01  vl 1.2931e+00  ema 1.2936e+00\n",
            "[hold 60] step 1600  rec 1.0107e+00  vl 1.2908e+00  ema 1.2912e+00\n",
            "[hold 60] step 1800  rec 9.7830e-01  vl 1.2876e+00  ema 1.2885e+00\n",
            "[hold 60] step 2000  rec 9.7263e-01  vl 1.2847e+00  ema 1.2855e+00\n",
            "[hold 60] step 2200  rec 9.8796e-01  vl 1.2818e+00  ema 1.2822e+00\n",
            "[hold 60] step 2400  rec 9.4196e-01  vl 1.2772e+00  ema 1.2784e+00\n",
            "[hold 60] step 2600  rec 1.0559e+00  vl 1.2730e+00  ema 1.2741e+00\n",
            "[hold 60] step 2800  rec 1.0091e+00  vl 1.2673e+00  ema 1.2689e+00\n",
            "[hold 60] step 3000  rec 9.1746e-01  vl 1.2609e+00  ema 1.2625e+00\n",
            "[hold 60] step 3200  rec 9.6481e-01  vl 1.2526e+00  ema 1.2547e+00\n",
            "[hold 60] step 3400  rec 1.0059e+00  vl 1.2419e+00  ema 1.2447e+00\n",
            "[hold 60] step 3600  rec 9.8092e-01  vl 1.2280e+00  ema 1.2316e+00\n",
            "[hold 60] step 3800  rec 9.5148e-01  vl 1.2090e+00  ema 1.2139e+00\n",
            "[hold 60] step 4000  rec 9.0706e-01  vl 1.1840e+00  ema 1.1904e+00\n",
            "[hold 60] step 4200  rec 8.5546e-01  vl 1.1465e+00  ema 1.1565e+00\n",
            "[hold 60] step 4400  rec 8.0824e-01  vl 1.0934e+00  ema 1.1077e+00\n",
            "[hold 60] step 4600  rec 7.2027e-01  vl 1.0174e+00  ema 1.0380e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Minimal coordinate-MLP for UV-Vis: f([lambda, c]) -> absorbance ===\n",
        "# This cell is your provided code (unaltered in logic), plus a short block at the end\n",
        "# that: (1) shows plots inline and (2) saves them to Drive and /mnt/data.\n",
        "#\n",
        "# If in Colab, make sure you have already mounted Drive:\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "import os, json, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch, torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# Repro\n",
        "SEED = 1337\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "ROOT = \"/content/drive/MyDrive/ArsenicSTS\"\n",
        "DATA_CSV = f\"{ROOT}/UVVisData/0.30MB_AuNP_As.csv\"\n",
        "\n",
        "# ---- Load CSV and make baseline-corrected matrix A[601,6] ----\n",
        "def load_uvvis(path, baseline_correct=True):\n",
        "    df = pd.read_csv(path)\n",
        "    df.columns = [str(c).strip() for c in df.columns]\n",
        "    wl = df[\"Wavelength\"].to_numpy().astype(np.float32)\n",
        "    conc_cols = []\n",
        "    for c in df.columns:\n",
        "        if c == \"Wavelength\":\n",
        "            continue\n",
        "        try:\n",
        "            float(c); conc_cols.append(c)\n",
        "        except:\n",
        "            pass\n",
        "    conc_vals = np.array(sorted([float(c) for c in conc_cols], key=float), dtype=np.float32)\n",
        "    cols_sorted = [str(int(c)) if float(c).is_integer() else str(c) for c in conc_vals]\n",
        "    A = np.stack([df[c].to_numpy().astype(np.float32) for c in cols_sorted], axis=1)  # [601,6]\n",
        "    if baseline_correct:\n",
        "        idx_800 = int(np.argmin(np.abs(wl - 800.0)))\n",
        "        A = A - A[idx_800:idx_800+1, :]\n",
        "    return wl, conc_vals, A\n",
        "\n",
        "wl, concs, A = load_uvvis(DATA_CSV, baseline_correct=True)\n",
        "assert wl.shape[0] == 601 and A.shape == (601, len(concs))\n",
        "C_MIN, C_MAX = float(concs.min()), float(concs.max())\n",
        "\n",
        "# ---- Build coordinate dataset: X=[lambda_norm, c_norm], y=absorbance ----\n",
        "lam_norm = (wl - wl.min()) / (wl.max() - wl.min() + 1e-12)  # [601]\n",
        "c_norm   = (concs - C_MIN) / (C_MAX - C_MIN + 1e-12)        # [6]\n",
        "\n",
        "Xs, ys = [], []\n",
        "for j, cn in enumerate(c_norm):\n",
        "    lam_grid = np.repeat(lam_norm[:, None], 1, axis=1)[:, 0]            # [601]\n",
        "    c_grid   = np.full_like(lam_grid, fill_value=cn, dtype=np.float32)  # [601]\n",
        "    Xs.append(np.stack([lam_grid, c_grid], axis=1))                      # [601,2]\n",
        "    ys.append(A[:, j])                                                   # [601]\n",
        "X = np.concatenate(Xs, axis=0).astype(np.float32)  # [601*6, 2]\n",
        "y = np.concatenate(ys, axis=0).astype(np.float32)  # [601*6]\n",
        "\n",
        "# Simple global scaling of y is optional. Often not needed. Keep identity:\n",
        "y_mean, y_std = 0.0, 1.0\n",
        "# If you see instability, uncomment:\n",
        "# y_mean, y_std = float(y.mean()), float(y.std() + 1e-6)\n",
        "# y = (y - y_mean) / y_std\n",
        "\n",
        "# Small train-val split\n",
        "n = X.shape[0]\n",
        "idx = np.arange(n); np.random.shuffle(idx)\n",
        "n_val = max(600, int(0.1 * n))\n",
        "val_idx, train_idx = idx[:n_val], idx[n_val:]\n",
        "Xtr, ytr = X[train_idx], y[train_idx]\n",
        "Xva, yva = X[val_idx], y[val_idx]\n",
        "\n",
        "train_loader = DataLoader(TensorDataset(torch.from_numpy(Xtr), torch.from_numpy(ytr)),\n",
        "                          batch_size=1024, shuffle=True, drop_last=False)\n",
        "val_loader   = DataLoader(TensorDataset(torch.from_numpy(Xva), torch.from_numpy(yva)),\n",
        "                          batch_size=2048, shuffle=False, drop_last=False)\n",
        "\n",
        "# ---- Tiny MLP ----\n",
        "class CoordMLP(nn.Module):\n",
        "    def __init__(self, hidden=128, depth=3):\n",
        "        super().__init__()\n",
        "        layers = [nn.Linear(2, hidden), nn.SiLU()]\n",
        "        for _ in range(depth-1):\n",
        "            layers += [nn.Linear(hidden, hidden), nn.SiLU()]\n",
        "        layers += [nn.Linear(hidden, 1)]\n",
        "        self.net = nn.Sequential(*layers)\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "model = CoordMLP(hidden=128, depth=3).to(DEVICE)\n",
        "opt = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-6)\n",
        "mse = nn.MSELoss()\n",
        "\n",
        "# Optional smoothness on lambda via finite diff on a dense lambda grid\n",
        "def lambda_smooth_penalty(net, c_val_norm, lam_n=601, w=0.0):\n",
        "    if w <= 0.0:\n",
        "        return torch.tensor(0.0, device=DEVICE)\n",
        "    lam = torch.linspace(0.0, 1.0, lam_n, device=DEVICE)[:, None]  # [L,1]\n",
        "    cvec = torch.full_like(lam, fill_value=c_val_norm)             # [L,1]\n",
        "    inp = torch.cat([lam, cvec], dim=1)\n",
        "    A_pred = net(inp).squeeze(1)                                   # [L]\n",
        "    d2 = A_pred[:-2] - 2*A_pred[1:-1] + A_pred[2:]\n",
        "    return w * (d2.pow(2).mean())\n",
        "\n",
        "# ---- Train ----\n",
        "best_val = float(\"inf\")\n",
        "patience, bad = 100, 0\n",
        "for epoch in range(2000):\n",
        "    model.train()\n",
        "    for xb, yb in train_loader:\n",
        "        xb = xb.to(DEVICE); yb = yb.to(DEVICE)\n",
        "        pred = model(xb).squeeze(1)\n",
        "        loss = mse(pred, yb)\n",
        "        opt.zero_grad(set_to_none=True); loss.backward(); opt.step()\n",
        "    # val\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        vs, ncount = 0.0, 0\n",
        "        for xb, yb in val_loader:\n",
        "            xb = xb.to(DEVICE); yb = yb.to(DEVICE)\n",
        "            pred = model(xb).squeeze(1)\n",
        "            vs += mse(pred, yb).item() * xb.size(0)\n",
        "            ncount += xb.size(0)\n",
        "        vloss = vs / ncount\n",
        "    if vloss + 1e-7 < best_val:\n",
        "        best_val = vloss; bad = 0\n",
        "        best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
        "    else:\n",
        "        bad += 1\n",
        "    if (epoch+1) % 100 == 0:\n",
        "        print(f\"epoch {epoch+1}  train {float(loss):.4e}  val {vloss:.4e}\")\n",
        "    if bad >= patience:\n",
        "        print(f\"Early stop at {epoch+1}, best val {best_val:.4e}\")\n",
        "        break\n",
        "\n",
        "# Restore best\n",
        "model.load_state_dict(best_state)\n",
        "\n",
        "# ---- Helper: predict full spectrum at any c* ----\n",
        "def predict_spectrum(model, wl_nm, c_star):\n",
        "    lam_n = (wl_nm - wl_nm.min()) / (wl_nm.max() - wl_nm.min() + 1e-12)\n",
        "    c_n = np.full_like(lam_n, fill_value=(c_star - C_MIN) / (C_MAX - C_MIN + 1e-12), dtype=np.float32)\n",
        "    Xq = torch.from_numpy(np.stack([lam_n.astype(np.float32), c_n], axis=1)).to(DEVICE)\n",
        "    with torch.no_grad():\n",
        "        yq = model(Xq).squeeze(1).cpu().numpy()\n",
        "    # invert scaling if you enabled it above\n",
        "    yq = yq * y_std + y_mean\n",
        "    return yq\n",
        "\n",
        "# ---- Quick sanity: RMSE on the six training concentrations ----\n",
        "def rmse(a,b): return float(np.sqrt(np.mean((a-b)**2)))\n",
        "\n",
        "for cj in concs:\n",
        "    y_hat = predict_spectrum(model, wl, float(cj))\n",
        "    err = rmse(A[:, list(concs).index(cj)], y_hat)\n",
        "    print(f\"RMSE at c={int(cj)}: {err:.5f}\")\n",
        "\n",
        "# Example prediction at an intermediate concentration\n",
        "c_star = 25.0\n",
        "A_hat = predict_spectrum(model, wl, c_star)\n",
        "print(\"Predicted spectrum at c=25 has shape:\", A_hat.shape)\n",
        "\n",
        "# ===================================================================\n",
        "# Extra block: plot inline and save to Drive and /mnt/data\n",
        "# ===================================================================\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "drive_dir = os.path.join(ROOT, \"UVVisImgs\")\n",
        "local_dir = \"/mnt/data/UVVisImgs\"\n",
        "os.makedirs(drive_dir, exist_ok=True)\n",
        "os.makedirs(local_dir, exist_ok=True)\n",
        "\n",
        "def save_both(fig, name):\n",
        "    drive_path = os.path.join(drive_dir, name)\n",
        "    local_path = os.path.join(local_dir, name)\n",
        "    fig.savefig(drive_path, dpi=160, bbox_inches=\"tight\")\n",
        "    fig.savefig(local_path, dpi=160, bbox_inches=\"tight\")\n",
        "    print(f\"Saved: {drive_path}\")\n",
        "    print(f\"Saved: {local_path}\")\n",
        "\n",
        "# Plot all measured spectra\n",
        "fig1 = plt.figure(figsize=(7,4.5))\n",
        "for j, c in enumerate(concs):\n",
        "    plt.plot(wl, A[:, j], label=f\"c={int(c)}\")\n",
        "plt.xlabel(\"Wavelength (nm)\")\n",
        "plt.ylabel(\"Absorbance\")\n",
        "plt.title(\"Measured spectra\")\n",
        "plt.legend(ncol=3, fontsize=8)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "save_both(fig1, \"measured_spectra.png\")\n",
        "\n",
        "# Plot model fit vs true at measured concentrations\n",
        "fig2 = plt.figure(figsize=(7,4.5))\n",
        "for j, c in enumerate(concs):\n",
        "    A_pred_j = predict_spectrum(model, wl, float(c))\n",
        "    plt.plot(wl, A[:, j], label=f\"true {int(c)}\", alpha=0.6)\n",
        "    plt.plot(wl, A_pred_j, label=f\"pred {int(c)}\", linestyle=\"--\", alpha=0.9)\n",
        "plt.xlabel(\"Wavelength (nm)\")\n",
        "plt.ylabel(\"Absorbance\")\n",
        "plt.title(\"Model fit vs true at measured concentrations\")\n",
        "plt.legend(ncol=3, fontsize=7)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "save_both(fig2, \"fit_vs_true.png\")\n",
        "\n",
        "# Plot prediction for c=25\n",
        "fig3 = plt.figure(figsize=(7,4.5))\n",
        "plt.plot(wl, A_hat, label=\"pred c=25\")\n",
        "plt.xlabel(\"Wavelength (nm)\")\n",
        "plt.ylabel(\"Absorbance\")\n",
        "plt.title(\"Predicted spectrum at c=25\")\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "save_both(fig3, \"pred_c25.png\")\n",
        "\n",
        "# Save c=25 as CSV\n",
        "pred_csv_drive = os.path.join(drive_dir, \"pred_c25.csv\")\n",
        "pred_csv_local = os.path.join(local_dir, \"pred_c25.csv\")\n",
        "np.savetxt(pred_csv_drive, np.column_stack([wl, A_hat]), delimiter=\",\", header=\"Wavelength,Absorbance\", comments=\"\")\n",
        "np.savetxt(pred_csv_local, np.column_stack([wl, A_hat]), delimiter=\",\", header=\"Wavelength,Absorbance\", comments=\"\")\n",
        "print(f\"Saved: {pred_csv_drive}\")\n",
        "print(f\"Saved: {pred_csv_local}\")"
      ],
      "metadata": {
        "id": "DHpht9QbfM8r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}